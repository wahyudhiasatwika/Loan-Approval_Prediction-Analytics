# -*- coding: utf-8 -*-
"""DBS_Machine Learning Terapan_Wahyu Dhia Satwika_Submission1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-XXybRNC2k8RjIfW4yzkatVLWrPfOa90

# Predictive Analytics : Loan Approval Prediction

## Business Understanding

### Problem Statements
- Bagaimana cara menentukan kelayakan persetujuan pinjaman secara otomatis untuk mengurangi waktu proses dan meminimalkan risiko kredit macet?
- Faktor apa saja yang paling berpengaruh dalam menentukan apakah pinjaman layak disetujui?

### Goals
- Mengembangkan model prediksi yang mampu menentukan status persetujuan pinjaman dengan akurasi tinggi.
- Mengidentifikasi faktor-faktor kunci yang memengaruhi kelayakan pinjaman sehingga dapat digunakan untuk mengoptimalkan proses persetujuan.

### Solution Statements
- Membangun model machine learning untuk klasifikasi persetujuan pinjaman.
- Menganalisis variabel yang ada di dalam dataset untuk menemukan fitur-fitur yang paling berpengaruh dalam keputusan persetujuan pinjaman.

## Data Understanding
Dataset Loan Approval yang berasal dari kaggle merupakan sebuah dataset sintetis yang berdasarkan dari [_(Sumber Utama)_] (https://www.kaggle.com/datasets/laotse/credit-risk-dataset). Dataset Loan Approval memiiliki 45000 records dengan 14 variabel, dengan rincian sebagai berikut:

## Data Understanding
Pada tahap ini dilakukan proses analisis untuk memahami dataset secara mendalam

### Data Loading

#### Import Library
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
import warnings
warnings.filterwarnings("ignore")

data = pd.read_csv("/content/loan_data.csv")

data

"""### Exploratory Data Analysis
Pada tahap ini dilakukan analisis untuk data yang ada di dalam dataset seperti dilihat
"""

data.shape

data.info()

"""Output di atas menunjukkan bahwa dataset memiliki 45000 data dan 14 kolom.
- Terdapat 6 tipe data float64
- Terdapat 3 tipe data int64
- Terdapat 5 tipe data object
"""

data.describe()

"""Fungsi describe digunakan untuk memberikan informasi statistik.

- Count adalah jumlah sampel pada data.
- Mean adalah nilai rata-rata.
- Std adalah standar deviasi.
- Min yaitu nilai minimum.
- 25% adalah kuartil pertama.
- 50% adalah kuartil kedua.
- 75% adalah kuartil ketiga.
- Max adalah nilai maksimum.
"""

unique_ages = data['person_age'].unique()
print(unique_ages)

"""Dapat dilihat pada output di atas, dataset memiliki data untuk umur pengguna dengan rentang 21 hingga 144 dimana umur 144 hampir tidak mungkin terjadi di dunia nyata. Oleh karena itu, dijadikan acuan untuk umur loan approval adalah 21 - 65 tahun seperti dibawah ini"""

data_fixed = data[data['person_age'] <= 65]

data_fixed.shape

"""#### Handling Missing Value"""

print("Total Data Duplikat:",data.duplicated().sum())

data_fixed.isnull().sum()

"""Dapat dilihat dari hasil di atas bahwa dataset tidak memiliki data duplikat dan missing value. Oleh karena itu, proses dapat dilanjutkan kepada visualisasi data

#### Handling Outliers
"""

categorical_feature = [
    "person_gender",
    "person_education",
    "person_home_ownership",
    "loan_intent",
    "previous_loan_defaults_on_file"
]

numerical_feature = [
    "person_age",
    "person_income",
    "person_emp_exp",
    "loan_amnt",
    "loan_int_rate",
    "loan_percent_income",
    "cb_person_cred_hist_length",
    "credit_score"
]

"""Untuk mempermudah visualisasi data, maka di feature dibagi menjadi categorical_feature dan numerical_feature"""

for num in numerical_feature:
    plt.figure(figsize=(10, 5))
    sns.boxplot(data=data_fixed, x=num, color='skyblue')
    plt.title(f'Boxplot of {num}')
    plt.xlabel(num)
    plt.show()

"""Di beberapa visual boxplot terdapat banyak sekali outlier. Oleh karena itu, untuk mendapatkan hasil yang lebih akurat maka perlu dihilangkan outlier tersebut"""

selected_cols = data_fixed[numerical_feature]

Q1 = selected_cols.quantile(0.25)
Q3 = selected_cols.quantile(0.75)
IQR = Q3 - Q1

df = data_fixed[~((selected_cols < (Q1 - 1.5 * IQR)) | (selected_cols > (Q3 + 1.5 * IQR))).any(axis=1)]

"""Pada tahap ini dilakukan filtering outliers untuk disimpan ke dalam dataframe"""

df.shape

"""Dapat dilihat setelah dilakukan filter untuk outliers menjadi 37549 data. Hasil Boxplot setelah difilter dapat dilihat di bawah ini."""

for num in numerical_feature:
    plt.figure(figsize=(10, 5))
    sns.boxplot(data=df, x=num, color='skyblue')
    plt.title(f'Boxplot of {num}')
    plt.xlabel(num)
    plt.show()

"""Untuk rata-rata distribusi box plot dapat dilihat sebagai berikut:
- person_age : rata-rata penggunaan loan_approval yaitu dari 23-28 tahun.
- person_income : rata-rata pengguna loan approval memiliki income sebesar 45000 - 85000.
- person_emp_exp : rata-rata pengalaman pekerjaan yang dimiliki oleh pengaju loan_approval adalah 1-7 tahun.
- loan_amnt : rata-rata pinjaman yang diminta yaitu 5000-13000
- loan_int_rate : rata-rata suku bunga pinjaman yang dimiliki berada pada angka 8.5-13
- loan_percent_income : rata-rata dari persentase pendapatan tahunan berada pada angka 0.07 - 0.18
- cb_person_cred_hist_length : rata-rata lama riwayat kredit yaitu 3 - 7 tahun
- credit_score : rata-rata skor kredit pengaju loan yaitu 600 - 660.

### EDA - Univariate Analysis
"""

# Univariate Analysis - Numerical Feature

sns.set(style="whitegrid")
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
fig.suptitle('Distribution of Numerical Features')

# Age
sns.histplot(df['person_age'], kde=True, ax=axes[0, 0])
axes[0, 0].set_title('Age Distribution')

# Income
sns.histplot(df['person_income'], kde=True, ax=axes[0, 1])
axes[0, 1].set_title('Income Distribution')

# Loan amount
sns.histplot(df['loan_amnt'], kde=True, ax=axes[0, 2])
axes[0, 2].set_title('Loan Amount Distribution')

# Interest rate
sns.histplot(df['loan_int_rate'], kde=True, ax=axes[1, 0])
axes[1, 0].set_title('Interest Rate Distribution')

# Credit score
sns.histplot(df['credit_score'], kde=True, ax=axes[1, 1])
axes[1, 1].set_title('Credit Score Distribution')

# Loan percent income
sns.histplot(df['loan_percent_income'], kde=True, ax=axes[1, 2])
axes[1, 2].set_title('Loan Percent Income Distribution')

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""- person_age : Distribusi dari umur memiliki angka tertinggi pada 23-24 tahun.
- person_income : Distribusi pendapatan pengaju memiliki angka terbanyak pada jangka 40000-70000
- loan_amnt : Distribusi permintaan loan memiliki angka tertinggi pada 500 dan 10000.
- loan_int_rate : Distribusi suku bunga pinjaman memiliki angka tertinggi pada angka 11
- credit_score : Distribusi skor kredit terdapat pada jangka angka 600-700.
- loan_percent_income: Distribusi jumlah pinjaman sebagai persentase dari pendapat tahunan memiliki angka tertinggi pada 0.05 - 0.15.
"""

# Univariate Analysis - Multivariate analysis

fig, axes = plt.subplots(2, 3, figsize=(15, 10))
fig.suptitle('Count Plots for Categorical Features')

# Gender
sns.countplot(data=df, x='person_gender', ax=axes[0, 0])
axes[0, 0].set_title('Gender Distribution')

# Education level
sns.countplot(data=df, x='person_education', ax=axes[0, 1])
axes[0, 1].set_title('Education Level Distribution')
axes[0, 1].tick_params(axis='x', rotation=45)

# Home ownership
sns.countplot(data=df, x='person_home_ownership', ax=axes[0, 2])
axes[0, 2].set_title('Home Ownership Distribution')

# Loan intent
sns.countplot(data=df, x='loan_intent', ax=axes[1, 0])
axes[1, 0].set_title('Loan Intent Distribution')
axes[1, 0].tick_params(axis='x', rotation=45)

# Previous loan
sns.countplot(data=df, x='previous_loan_defaults_on_file', ax=axes[1, 1])
axes[1, 1].set_title('Previous Loan Defaults')

# Loan status
sns.countplot(data=df, x='loan_status', ax=axes[1, 2])
axes[1, 2].set_title('Loan Status')

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""Feature yang memiliki variasi terbanyak yaitu pada person_education, person_home_ownership, dan loan_intent.
- person_education : Angka tertinggi yaitu pada Bachelor dan disusul dengan High School dan Associate.
- person_home_ownership : Rata-rata dari pengaju loan yaitu bertempat tinggal rent dan mortgage.
- loan_intent : Angka tertinggi pada pengaju loan yaitu untuk education dan medical.

#### EDA - Multivariate Analysis
"""

for col in categorical_feature:
    plt.figure(figsize=(8, 5))
    sns.countplot(data=data, x=col, hue='loan_status', palette='Set2')
    plt.title(f"Distribution of {col} by Loan Status")
    plt.xlabel(col)
    plt.ylabel("Count")
    plt.legend(title="Loan Status", loc='upper right')
    plt.xticks(rotation=45)
    plt.show()

"""- person_gender : Jenis kelamin tidak memiliki pengaruh besar dalam penerimaan pengajuan loan.
- person_education : Yang paling banyak diterima dalam pengajuan loan yaitu untuk Rent.
- loan_intent : Penerimaan loan paling banyak diterima untuk tujuan medical dan debtconsolidation
- previous_loan_default_on_file : Yang paling banyak diterima untuk pengajuan loan yaitu yang memiliki indikator peminjaman sebelumnya adalah "no".

#### Correlation Matrix

Visualisasi ini digunakan untuk mencari tahu feature apa saja yang memiliki korelasi paling besar.
"""

numeric_df = df.select_dtypes(include=['number'])

plt.figure(figsize=(12, 8))
correlation_matrix = numeric_df.corr()

# Heatmap correlation matrix
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap of Numerical Features")
plt.show()

"""Feature Numerik yang memiliki korelasi paling besar yaitu loan_int_rate dengan skor sebesar 0.32 dan loan_percent_income sebesar 0.35.

### Data Preparation
Teknik yang digunakan:
- Label Encoding : Mengubah kategori menjadi tipe data numerik
- Train-test split data : Data dibagi menjadi 80% Train dan 20% Test
"""

data_encoded = df.copy()

label_encoder = LabelEncoder()
for column in ['person_gender', 'person_education', 'person_home_ownership', 'loan_intent', 'previous_loan_defaults_on_file']:
    data_encoded[column] = label_encoder.fit_transform(data_encoded[column])

"""Untuk feature categorical seperti umur, edukasi, kepimilikan tempat tinggal, tujuan loan, indikator default peminjaman sebelumnya akan diubah menjadi angka menggunakan LabelEncoder()"""

data_encoded.head()

# Separate features and target variable
X = data_encoded.drop(columns=['loan_status'])
y = data_encoded['loan_status']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Dataset dibagi untuk feature menjadi variable X dan label menjadi variabel y. Untuk train dibagi menjadi 80% dan test 20%."""

X

y

models = {
    "Random Forest": RandomForestClassifier(),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(),
    "Support Vector Classifier": SVC(),
    "K-Nearest Neighbors": KNeighborsClassifier()
}

"""Digunakan 5 model yaitu Random Forest, Logistic Regression, Decision Tree, SVC, dan KNN untuk mencari tahu model yang terbaik.
1. Random Forest adalah algoritma ensemble berbasis pohon keputusan. Algoritma ini membangun banyak pohon keputusan secara acak pada subset data, kemudian menggabungkan hasil prediksi dari masing-masing pohon dengan metode voting

2. Logistic Regression adalah model statistik yang digunakan untuk klasifikasi biner. Model ini memperkirakan probabilitas kelas menggunakan fungsi sigmoid.

3. Decision Tree adalah algoritma yang membagi data ke dalam kelompok berdasarkan fitur dengan aturan "if-then". Algoritma ini membuat keputusan dengan struktur pohon.

4. Support Vector Classifier adalah algoritma berbasis Support Vector Machine (SVM) yang mencari hyperplane optimal untuk memisahkan kelas dalam dataset.

5. K-Nearest Neighbors (KNN) adalah algoritma berbasis instance yang mengklasifikasikan data baru berdasarkan jarak (misalnya, Euclidean) ke ùëò tetangga terdekat.
"""

# KFold Cross-Validation
kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
results = {}

for name, model in models.items():
    # Train the model
    model.fit(X_train, y_train)

    # Train accuracy
    train_accuracy = model.score(X_train, y_train)

    # K-Fold cross-validation accuracy
    kfold_scores = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')
    kfold_accuracy = np.mean(kfold_scores)

    # Simpan Hasil
    results[name] = {
        "Train Accuracy": train_accuracy,
        "KFold Accuracy": kfold_accuracy
    }

    print(f"{name}:")
    print(f"  Train Accuracy: {train_accuracy:.4f}")
    print(f"  K-Fold Accuracy: {kfold_accuracy:.4f}")

"""Pada evaluasi digunakan 5 fold yang artinya dataset akan dibagi menjadi 5 subset


#### Alasan Memakai Evaluasi K-Fold Cross Validation

- Membagi data menjadi beberapa lipatan memungkinkan evaluasi model yang lebih konsisten karena setiap data akan digunakan sebagai data latih dan data uji.
- Dengan melakukan evaluasi pada berbagai subset data, K-Fold Cross-Validation mengurangi bias yang mungkin muncul akibat pembagian data secara acak.
- Memberikan gambaran model nantinya akan bekerja untuk data yang baru.

"""

sorted_results = sorted(results.items(), key=lambda x: x[1]["KFold Accuracy"], reverse=True)

print("\nTop 2 Models Based on K-Fold Accuracy:")
for name, metrics in sorted_results[:2]:
    print(f"{name}:")
    print(f"  Train Accuracy: {metrics['Train Accuracy']:.4f}")
    print(f"  K-Fold Accuracy: {metrics['KFold Accuracy']:.4f}")

"""Dua Algoritma Terbaik yang didapatkan untuk dataset ini yaitu Random Forest dan Decision Tree

####  Random Forest
Kelebihan :
- Random Forest lebih tahan terhadap overfitting
- Random Forest lebih tahan terhadap outlier dan noise dalam data
- Cocok untuk dataset besar dan kompleks
- Random Forest dapat memberikan estimasi pentingnya setiap fitur dalam membuat prediksi

Kekurangan :
- Pelatihan Random Forest memakan waktu dan memori lebih besar karena melibatkan banyak pohon.
- Dibandingkan Decision Tree tunggal, Random Forest lebih sulit diinterpretasikan karena sifatnya sebagai ensemble.

#### Decision Tree
Kelebihan:
- Decision Tree bekerja dengan baik tanpa memerlukan normalisasi atau standarisasi data.
- Decision Tree secara dapat menangani data kategori tanpa memerlukan encoding khusus.

Kekurangan:
- Decision Tree cenderung overfit jika pohon terlalu dalam.
- Untuk dataset besar atau kompleks, Decision Tree dapat menjadi lambat.

"""